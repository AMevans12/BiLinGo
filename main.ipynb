{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription:  A quick brown fox jumps over a lazy dog.\n",
      "Phonetic Transcription: AH0 K W IH1 K B R AW1 N F AA1 K S JH AH1 M P S OW1 V ER0 AH0 L EY1 Z IY0 dog.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pronouncing\n",
    "\n",
    "# Function to transcribe audio using Whisper\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")  # Model options: tiny, base, small, medium, large\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Function to convert text to phonemes using pronouncing\n",
    "def text_to_phonemes(text):\n",
    "    words = text.split()  # Split text into words\n",
    "    phonemes = []\n",
    "    \n",
    "    for word in words:\n",
    "        phones = pronouncing.phones_for_word(word)  # Get phonetic transcription for each word\n",
    "        if phones:\n",
    "            phonemes.append(phones[0])  # Append the first result if available\n",
    "        else:\n",
    "            phonemes.append(word)  # In case no phoneme is found, keep the original word\n",
    "\n",
    "    return \" \".join(phonemes)\n",
    "\n",
    "# Path to your audio file\n",
    "audio_file = \"saq_1.mp3\"  # Change this to your actual file\n",
    "\n",
    "# Transcribe and convert to phonemes\n",
    "transcription = transcribe_audio(audio_file)\n",
    "phonemes = text_to_phonemes(transcription)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTranscription:\", transcription)\n",
    "print(\"Phonetic Transcription:\", phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription:  A quick brown fox jumps over a lazy dog.\n",
      "IPA Phonetic Transcription: ə kwɪk braʊn fɑks ʤəmps ˈoʊvər ə ˈleɪzi dɔg.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import eng_to_ipa as ipa  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")  \n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "def text_to_ipa(text):\n",
    "    words = text.split()  \n",
    "    ipa_transcription = []\n",
    "    \n",
    "    \n",
    "    for word in words:\n",
    "        ipa_word = ipa.convert(word)  \n",
    "        ipa_transcription.append(ipa_word)\n",
    "    \n",
    "    return \" \".join(ipa_transcription)\n",
    "\n",
    "\n",
    "audio_file = \"saq_2.mp3\"  \n",
    "\n",
    "\n",
    "transcription = transcribe_audio(audio_file)\n",
    "ipa_phonemes = text_to_ipa(transcription)\n",
    "\n",
    "\n",
    "print(\"\\nTranscription:\", transcription)\n",
    "print(\"IPA Phonetic Transcription:\", ipa_phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎙 **Audio 1 Transcription:**  A quick brown fox jumps over a lazy dog.\n",
      "🔠 **IPA Phonetic Transcription:** ə kwɪk braʊn fɑks ʤəmps ˈoʊvər ə ˈleɪzi dɔg.\n",
      "📝 **Simplified Phonetic Transcription:** ooh kweehk braoon fahks joohmps ooovoohr ooh leeehzee dorg.\n",
      "\n",
      "🎙 **Audio 2 Transcription:**  The quick brown fox jumps over the lazy dog.\n",
      "🔠 **IPA Phonetic Transcription:** ðə kwɪk braʊn fɑks ʤəmps ˈoʊvər ðə ˈleɪzi dɔg.\n",
      "📝 **Simplified Phonetic Transcription:** dhooh kweehk braoon fahks joohmps ooovoohr dhooh leeehzee dorg.\n",
      "\n",
      "🔍 **Phonetic Comparison Results** 🔍\n",
      "🔹 **Similarity Ratio:** 96.72%\n",
      "🔹 **Levenshtein Distance:** 4 changes required\n",
      "\n",
      "🔹 **Differences Highlighted:**\n",
      "❌ ooh  →  ✅ dhooh\n",
      "❌ ooh  →  ✅ dhooh\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import eng_to_ipa as ipa\n",
    "import warnings\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")  \n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "def text_to_ipa(text):\n",
    "    words = text.split()  \n",
    "    ipa_transcription = [ipa.convert(word) for word in words]\n",
    "    return \" \".join(ipa_transcription)\n",
    "\n",
    "\n",
    "def simplify_ipa(ipa_text):\n",
    "    ipa_mapping = {\n",
    "        \"æ\": \"a\", \"ɑ\": \"ah\", \"ɒ\": \"aw\", \"ɔ\": \"or\", \"ə\": \"uh\", \"ɛ\": \"eh\", \"ɜ\": \"ur\",\n",
    "        \"ɪ\": \"ih\", \"i\": \"ee\", \"ʊ\": \"oo\", \"u\": \"oo\", \"ʌ\": \"uh\", \n",
    "        \"ʒ\": \"zh\", \"ʃ\": \"sh\", \"θ\": \"th\", \"ð\": \"dh\", \"ŋ\": \"ng\", \"ɹ\": \"r\", \n",
    "        \"ʤ\": \"j\", \"ʧ\": \"ch\", \"ɡ\": \"g\", \"dʒ\": \"j\", \"tʃ\": \"ch\",\n",
    "        \"aʊ\": \"ow\", \"oʊ\": \"oh\", \"eɪ\": \"ay\", \"aɪ\": \"eye\",\n",
    "        \"ˈ\": \"\", \"ˌ\": \"\", \"ː\": \"\"\n",
    "    }\n",
    "    \n",
    "    for ipa_char, simple_char in ipa_mapping.items():\n",
    "        ipa_text = ipa_text.replace(ipa_char, simple_char)\n",
    "\n",
    "    return ipa_text\n",
    "\n",
    "\n",
    "def compare_phonetics(phonetics1, phonetics2):\n",
    "    ratio = SequenceMatcher(None, phonetics1, phonetics2).ratio()  \n",
    "    lev_dist = levenshtein_distance(phonetics1, phonetics2)  \n",
    "    \n",
    "    print(\"\\n🔍 **Phonetic Comparison Results** 🔍\")\n",
    "    print(f\"🔹 **Similarity Ratio:** {ratio:.2%}\")  \n",
    "    print(f\"🔹 **Levenshtein Distance:** {lev_dist} changes required\")\n",
    "    \n",
    "    # Highlight differences\n",
    "    print(\"\\n🔹 **Differences Highlighted:**\")\n",
    "    for word1, word2 in zip(phonetics1.split(), phonetics2.split()):\n",
    "        if word1 != word2:\n",
    "            print(f\"❌ {word1}  →  ✅ {word2}\")\n",
    "\n",
    "\n",
    "audio_file1 = \"saq_1.mp3\"\n",
    "audio_file2 = \"aaq_1.mp3\"\n",
    "\n",
    "# Transcribe and convert to IPA\n",
    "transcription1 = transcribe_audio(audio_file1)\n",
    "ipa_phonemes1 = text_to_ipa(transcription1)\n",
    "simplified_phonetics1 = simplify_ipa(ipa_phonemes1)\n",
    "\n",
    "transcription2 = transcribe_audio(audio_file2)\n",
    "ipa_phonemes2 = text_to_ipa(transcription2)\n",
    "simplified_phonetics2 = simplify_ipa(ipa_phonemes2)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n🎙 **Audio 1 Transcription:**\", transcription1)\n",
    "print(\"🔠 **IPA Phonetic Transcription:**\", ipa_phonemes1)\n",
    "print(\"📝 **Simplified Phonetic Transcription:**\", simplified_phonetics1)\n",
    "\n",
    "print(\"\\n🎙 **Audio 2 Transcription:**\", transcription2)\n",
    "print(\"🔠 **IPA Phonetic Transcription:**\", ipa_phonemes2)\n",
    "print(\"📝 **Simplified Phonetic Transcription:**\", simplified_phonetics2)\n",
    "\n",
    "\n",
    "compare_phonetics(simplified_phonetics1, simplified_phonetics2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from speechbrain.inference.ASR import EncoderDecoderASR\n",
    "\n",
    "# asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-wav2vec2-commonvoice-en\", savedir=\"temp\")\n",
    "# asr_model.transcribe_file(\"saq_1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎙 **Audio 1 Transcription:** 晚上好,今天過得怎麼樣?\n",
      "🔠 **Pinyin Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   zen3 me yang4  ?\n",
      "📝 **Simplified Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   zen3 me yang4  ?\n",
      "\n",
      "🎙 **Audio 2 Transcription:** 晚上好,今天过得人美样。\n",
      "🔠 **Pinyin Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   ren2 mei3 yang4  。\n",
      "📝 **Simplified Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   ren2 mei3 yang4  。\n",
      "\n",
      "🔍 **Phonetic Comparison Results** 🔍\n",
      "🔹 **Similarity Ratio:** 93.75%\n",
      "🔹 **Levenshtein Distance:** 5 changes required\n",
      "\n",
      "🔹 **Differences Highlighted:**\n",
      "❌ zen3  →  ✅ ren2\n",
      "❌ me  →  ✅ mei3\n",
      "❌ ?  →  ✅ 。\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import jieba\n",
    "from pypinyin import pinyin, Style\n",
    "import warnings\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")\n",
    "    result = model.transcribe(audio_file, language=\"zh\")\n",
    "    return result[\"text\"]\n",
    "\n",
    "def segment_mandarin(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "def text_to_pinyin(text):\n",
    "    words = segment_mandarin(text)\n",
    "    pinyin_transcription = pinyin(words, style=Style.TONE3, heteronym=False)\n",
    "    return \" \".join([syllable[0] for syllable in pinyin_transcription])\n",
    "\n",
    "def simplify_pinyin(pinyin_text):\n",
    "    pinyin_mapping = {\n",
    "        \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\", \"5\": \"\",\n",
    "        \"ā\": \"a1\", \"á\": \"a2\", \"ǎ\": \"a3\", \"à\": \"a4\",\n",
    "        \"ē\": \"e1\", \"é\": \"e2\", \"ě\": \"e3\", \"è\": \"e4\",\n",
    "        \"ī\": \"i1\", \"í\": \"i2\", \"ǐ\": \"i3\", \"ì\": \"i4\",\n",
    "        \"ō\": \"o1\", \"ó\": \"o2\", \"ǒ\": \"o3\", \"ò\": \"o4\",\n",
    "        \"ū\": \"u1\", \"ú\": \"u2\", \"ǔ\": \"u3\", \"ù\": \"u4\",\n",
    "        \"ǖ\": \"ü1\", \"ǘ\": \"ü2\", \"ǚ\": \"ü3\", \"ǜ\": \"ü4\"\n",
    "    }\n",
    "    for pinyin_char, simple_char in pinyin_mapping.items():\n",
    "        pinyin_text = pinyin_text.replace(pinyin_char, simple_char)\n",
    "    return pinyin_text\n",
    "\n",
    "def compare_phonetics(phonetics1, phonetics2):\n",
    "    ratio = SequenceMatcher(None, phonetics1, phonetics2).ratio()\n",
    "    lev_dist = levenshtein_distance(phonetics1, phonetics2)\n",
    "    print(\"\\n🔍 **Phonetic Comparison Results** 🔍\")\n",
    "    print(f\"🔹 **Similarity Ratio:** {ratio:.2%}\")\n",
    "    print(f\"🔹 **Levenshtein Distance:** {lev_dist} changes required\")\n",
    "    print(\"\\n🔹 **Differences Highlighted:**\")\n",
    "    for word1, word2 in zip(phonetics1.split(), phonetics2.split()):\n",
    "        if word1 != word2:\n",
    "            print(f\"❌ {word1}  →  ✅ {word2}\")\n",
    "\n",
    "audio_file1 = \"aud_1.wav\"\n",
    "audio_file2 = \"saq_ch.mp3\"\n",
    "\n",
    "transcription1 = transcribe_audio(audio_file1)\n",
    "pinyin_phonetics1 = text_to_pinyin(transcription1)\n",
    "simplified_phonetics1 = simplify_pinyin(pinyin_phonetics1)\n",
    "\n",
    "transcription2 = transcribe_audio(audio_file2)\n",
    "pinyin_phonetics2 = text_to_pinyin(transcription2)\n",
    "simplified_phonetics2 = simplify_pinyin(pinyin_phonetics2)\n",
    "\n",
    "print(\"\\n🎙 **Audio 1 Transcription:**\", transcription1)\n",
    "print(\"🔠 **Pinyin Phonetic Transcription:**\", pinyin_phonetics1)\n",
    "print(\"📝 **Simplified Phonetic Transcription:**\", simplified_phonetics1)\n",
    "\n",
    "print(\"\\n🎙 **Audio 2 Transcription:**\", transcription2)\n",
    "print(\"🔠 **Pinyin Phonetic Transcription:**\", pinyin_phonetics2)\n",
    "print(\"📝 **Simplified Phonetic Transcription:**\", simplified_phonetics2)\n",
    "\n",
    "compare_phonetics(simplified_phonetics1, simplified_phonetics2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
