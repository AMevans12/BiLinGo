{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription:  A quick brown fox jumps over a lazy dog.\n",
      "Phonetic Transcription: AH0 K W IH1 K B R AW1 N F AA1 K S JH AH1 M P S OW1 V ER0 AH0 L EY1 Z IY0 dog.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pronouncing\n",
    "\n",
    "# Function to transcribe audio using Whisper\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")  # Model options: tiny, base, small, medium, large\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Function to convert text to phonemes using pronouncing\n",
    "def text_to_phonemes(text):\n",
    "    words = text.split()  # Split text into words\n",
    "    phonemes = []\n",
    "    \n",
    "    for word in words:\n",
    "        phones = pronouncing.phones_for_word(word)  # Get phonetic transcription for each word\n",
    "        if phones:\n",
    "            phonemes.append(phones[0])  # Append the first result if available\n",
    "        else:\n",
    "            phonemes.append(word)  # In case no phoneme is found, keep the original word\n",
    "\n",
    "    return \" \".join(phonemes)\n",
    "\n",
    "# Path to your audio file\n",
    "audio_file = \"saq_1.mp3\"  # Change this to your actual file\n",
    "\n",
    "# Transcribe and convert to phonemes\n",
    "transcription = transcribe_audio(audio_file)\n",
    "phonemes = text_to_phonemes(transcription)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTranscription:\", transcription)\n",
    "print(\"Phonetic Transcription:\", phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription:  A quick brown fox jumps over a lazy dog.\n",
      "IPA Phonetic Transcription: É™ kwÉªk braÊŠn fÉ‘ks Ê¤É™mps ËˆoÊŠvÉ™r É™ ËˆleÉªzi dÉ”g.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import eng_to_ipa as ipa  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")  \n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "def text_to_ipa(text):\n",
    "    words = text.split()  \n",
    "    ipa_transcription = []\n",
    "    \n",
    "    \n",
    "    for word in words:\n",
    "        ipa_word = ipa.convert(word)  \n",
    "        ipa_transcription.append(ipa_word)\n",
    "    \n",
    "    return \" \".join(ipa_transcription)\n",
    "\n",
    "\n",
    "audio_file = \"saq_2.mp3\"  \n",
    "\n",
    "\n",
    "transcription = transcribe_audio(audio_file)\n",
    "ipa_phonemes = text_to_ipa(transcription)\n",
    "\n",
    "\n",
    "print(\"\\nTranscription:\", transcription)\n",
    "print(\"IPA Phonetic Transcription:\", ipa_phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ™ **Audio 1 Transcription:**  A quick brown fox jumps over a lazy dog.\n",
      "ğŸ”  **IPA Phonetic Transcription:** É™ kwÉªk braÊŠn fÉ‘ks Ê¤É™mps ËˆoÊŠvÉ™r É™ ËˆleÉªzi dÉ”g.\n",
      "ğŸ“ **Simplified Phonetic Transcription:** ooh kweehk braoon fahks joohmps ooovoohr ooh leeehzee dorg.\n",
      "\n",
      "ğŸ™ **Audio 2 Transcription:**  The quick brown fox jumps over the lazy dog.\n",
      "ğŸ”  **IPA Phonetic Transcription:** Ã°É™ kwÉªk braÊŠn fÉ‘ks Ê¤É™mps ËˆoÊŠvÉ™r Ã°É™ ËˆleÉªzi dÉ”g.\n",
      "ğŸ“ **Simplified Phonetic Transcription:** dhooh kweehk braoon fahks joohmps ooovoohr dhooh leeehzee dorg.\n",
      "\n",
      "ğŸ” **Phonetic Comparison Results** ğŸ”\n",
      "ğŸ”¹ **Similarity Ratio:** 96.72%\n",
      "ğŸ”¹ **Levenshtein Distance:** 4 changes required\n",
      "\n",
      "ğŸ”¹ **Differences Highlighted:**\n",
      "âŒ ooh  â†’  âœ… dhooh\n",
      "âŒ ooh  â†’  âœ… dhooh\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import eng_to_ipa as ipa\n",
    "import warnings\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")  \n",
    "    result = model.transcribe(audio_file)\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "def text_to_ipa(text):\n",
    "    words = text.split()  \n",
    "    ipa_transcription = [ipa.convert(word) for word in words]\n",
    "    return \" \".join(ipa_transcription)\n",
    "\n",
    "\n",
    "def simplify_ipa(ipa_text):\n",
    "    ipa_mapping = {\n",
    "        \"Ã¦\": \"a\", \"É‘\": \"ah\", \"É’\": \"aw\", \"É”\": \"or\", \"É™\": \"uh\", \"É›\": \"eh\", \"Éœ\": \"ur\",\n",
    "        \"Éª\": \"ih\", \"i\": \"ee\", \"ÊŠ\": \"oo\", \"u\": \"oo\", \"ÊŒ\": \"uh\", \n",
    "        \"Ê’\": \"zh\", \"Êƒ\": \"sh\", \"Î¸\": \"th\", \"Ã°\": \"dh\", \"Å‹\": \"ng\", \"É¹\": \"r\", \n",
    "        \"Ê¤\": \"j\", \"Ê§\": \"ch\", \"É¡\": \"g\", \"dÊ’\": \"j\", \"tÊƒ\": \"ch\",\n",
    "        \"aÊŠ\": \"ow\", \"oÊŠ\": \"oh\", \"eÉª\": \"ay\", \"aÉª\": \"eye\",\n",
    "        \"Ëˆ\": \"\", \"ËŒ\": \"\", \"Ë\": \"\"\n",
    "    }\n",
    "    \n",
    "    for ipa_char, simple_char in ipa_mapping.items():\n",
    "        ipa_text = ipa_text.replace(ipa_char, simple_char)\n",
    "\n",
    "    return ipa_text\n",
    "\n",
    "\n",
    "def compare_phonetics(phonetics1, phonetics2):\n",
    "    ratio = SequenceMatcher(None, phonetics1, phonetics2).ratio()  \n",
    "    lev_dist = levenshtein_distance(phonetics1, phonetics2)  \n",
    "    \n",
    "    print(\"\\nğŸ” **Phonetic Comparison Results** ğŸ”\")\n",
    "    print(f\"ğŸ”¹ **Similarity Ratio:** {ratio:.2%}\")  \n",
    "    print(f\"ğŸ”¹ **Levenshtein Distance:** {lev_dist} changes required\")\n",
    "    \n",
    "    # Highlight differences\n",
    "    print(\"\\nğŸ”¹ **Differences Highlighted:**\")\n",
    "    for word1, word2 in zip(phonetics1.split(), phonetics2.split()):\n",
    "        if word1 != word2:\n",
    "            print(f\"âŒ {word1}  â†’  âœ… {word2}\")\n",
    "\n",
    "\n",
    "audio_file1 = \"saq_1.mp3\"\n",
    "audio_file2 = \"aaq_1.mp3\"\n",
    "\n",
    "# Transcribe and convert to IPA\n",
    "transcription1 = transcribe_audio(audio_file1)\n",
    "ipa_phonemes1 = text_to_ipa(transcription1)\n",
    "simplified_phonetics1 = simplify_ipa(ipa_phonemes1)\n",
    "\n",
    "transcription2 = transcribe_audio(audio_file2)\n",
    "ipa_phonemes2 = text_to_ipa(transcription2)\n",
    "simplified_phonetics2 = simplify_ipa(ipa_phonemes2)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nğŸ™ **Audio 1 Transcription:**\", transcription1)\n",
    "print(\"ğŸ”  **IPA Phonetic Transcription:**\", ipa_phonemes1)\n",
    "print(\"ğŸ“ **Simplified Phonetic Transcription:**\", simplified_phonetics1)\n",
    "\n",
    "print(\"\\nğŸ™ **Audio 2 Transcription:**\", transcription2)\n",
    "print(\"ğŸ”  **IPA Phonetic Transcription:**\", ipa_phonemes2)\n",
    "print(\"ğŸ“ **Simplified Phonetic Transcription:**\", simplified_phonetics2)\n",
    "\n",
    "\n",
    "compare_phonetics(simplified_phonetics1, simplified_phonetics2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from speechbrain.inference.ASR import EncoderDecoderASR\n",
    "\n",
    "# asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-wav2vec2-commonvoice-en\", savedir=\"temp\")\n",
    "# asr_model.transcribe_file(\"saq_1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ™ **Audio 1 Transcription:** æ™šä¸Šå¥½,ä»Šå¤©éå¾—æ€éº¼æ¨£?\n",
      "ğŸ”  **Pinyin Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   zen3 me yang4  ?\n",
      "ğŸ“ **Simplified Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   zen3 me yang4  ?\n",
      "\n",
      "ğŸ™ **Audio 2 Transcription:** æ™šä¸Šå¥½,ä»Šå¤©è¿‡å¾—äººç¾æ ·ã€‚\n",
      "ğŸ”  **Pinyin Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   ren2 mei3 yang4  ã€‚\n",
      "ğŸ“ **Simplified Phonetic Transcription:** wan3 shang4   hao3  ,  jin1 tian1   guo4 de2   ren2 mei3 yang4  ã€‚\n",
      "\n",
      "ğŸ” **Phonetic Comparison Results** ğŸ”\n",
      "ğŸ”¹ **Similarity Ratio:** 93.75%\n",
      "ğŸ”¹ **Levenshtein Distance:** 5 changes required\n",
      "\n",
      "ğŸ”¹ **Differences Highlighted:**\n",
      "âŒ zen3  â†’  âœ… ren2\n",
      "âŒ me  â†’  âœ… mei3\n",
      "âŒ ?  â†’  âœ… ã€‚\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import jieba\n",
    "from pypinyin import pinyin, Style\n",
    "import warnings\n",
    "from difflib import SequenceMatcher\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    model = whisper.load_model(\"medium\")\n",
    "    result = model.transcribe(audio_file, language=\"zh\")\n",
    "    return result[\"text\"]\n",
    "\n",
    "def segment_mandarin(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "def text_to_pinyin(text):\n",
    "    words = segment_mandarin(text)\n",
    "    pinyin_transcription = pinyin(words, style=Style.TONE3, heteronym=False)\n",
    "    return \" \".join([syllable[0] for syllable in pinyin_transcription])\n",
    "\n",
    "def simplify_pinyin(pinyin_text):\n",
    "    pinyin_mapping = {\n",
    "        \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\", \"5\": \"\",\n",
    "        \"Ä\": \"a1\", \"Ã¡\": \"a2\", \"Ç\": \"a3\", \"Ã \": \"a4\",\n",
    "        \"Ä“\": \"e1\", \"Ã©\": \"e2\", \"Ä›\": \"e3\", \"Ã¨\": \"e4\",\n",
    "        \"Ä«\": \"i1\", \"Ã­\": \"i2\", \"Ç\": \"i3\", \"Ã¬\": \"i4\",\n",
    "        \"Å\": \"o1\", \"Ã³\": \"o2\", \"Ç’\": \"o3\", \"Ã²\": \"o4\",\n",
    "        \"Å«\": \"u1\", \"Ãº\": \"u2\", \"Ç”\": \"u3\", \"Ã¹\": \"u4\",\n",
    "        \"Ç–\": \"Ã¼1\", \"Ç˜\": \"Ã¼2\", \"Çš\": \"Ã¼3\", \"Çœ\": \"Ã¼4\"\n",
    "    }\n",
    "    for pinyin_char, simple_char in pinyin_mapping.items():\n",
    "        pinyin_text = pinyin_text.replace(pinyin_char, simple_char)\n",
    "    return pinyin_text\n",
    "\n",
    "def compare_phonetics(phonetics1, phonetics2):\n",
    "    ratio = SequenceMatcher(None, phonetics1, phonetics2).ratio()\n",
    "    lev_dist = levenshtein_distance(phonetics1, phonetics2)\n",
    "    print(\"\\nğŸ” **Phonetic Comparison Results** ğŸ”\")\n",
    "    print(f\"ğŸ”¹ **Similarity Ratio:** {ratio:.2%}\")\n",
    "    print(f\"ğŸ”¹ **Levenshtein Distance:** {lev_dist} changes required\")\n",
    "    print(\"\\nğŸ”¹ **Differences Highlighted:**\")\n",
    "    for word1, word2 in zip(phonetics1.split(), phonetics2.split()):\n",
    "        if word1 != word2:\n",
    "            print(f\"âŒ {word1}  â†’  âœ… {word2}\")\n",
    "\n",
    "audio_file1 = \"aud_1.wav\"\n",
    "audio_file2 = \"saq_ch.mp3\"\n",
    "\n",
    "transcription1 = transcribe_audio(audio_file1)\n",
    "pinyin_phonetics1 = text_to_pinyin(transcription1)\n",
    "simplified_phonetics1 = simplify_pinyin(pinyin_phonetics1)\n",
    "\n",
    "transcription2 = transcribe_audio(audio_file2)\n",
    "pinyin_phonetics2 = text_to_pinyin(transcription2)\n",
    "simplified_phonetics2 = simplify_pinyin(pinyin_phonetics2)\n",
    "\n",
    "print(\"\\nğŸ™ **Audio 1 Transcription:**\", transcription1)\n",
    "print(\"ğŸ”  **Pinyin Phonetic Transcription:**\", pinyin_phonetics1)\n",
    "print(\"ğŸ“ **Simplified Phonetic Transcription:**\", simplified_phonetics1)\n",
    "\n",
    "print(\"\\nğŸ™ **Audio 2 Transcription:**\", transcription2)\n",
    "print(\"ğŸ”  **Pinyin Phonetic Transcription:**\", pinyin_phonetics2)\n",
    "print(\"ğŸ“ **Simplified Phonetic Transcription:**\", simplified_phonetics2)\n",
    "\n",
    "compare_phonetics(simplified_phonetics1, simplified_phonetics2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
